install.packages("rtweet")
library(rtweet)
lookup_users(users = "nytimes", token=token)
library(rtweet)
lookup_users(users = "nytimes")
get_timeline(user="nytimes", n=10)
users <- lists_members(list_id = 34179516)
head(users)
library(dplyr)
users %>% filter(statuses_count >= 100 & followers_count >= 100) %>% sample_n(100) -> users
#Your Code Here
timeline <- get_timeline(user=users$user_id[1], n=200, include_rts = F, token=token)
timeline <- get_timeline(user=users$user_id[1], n=200, include_rts = F)
head(timeline)
timelines <- get_timelines(user=users$user_id, n=200, include_rts = F)
#Your code here
timelines <- get_timelines(user=users$user_id, n=200, include_rts = F)
#Your code here
library(tidytext)
install.packages("tidytext")
library(tidytext)
?get_sentiments
library(syuzhet)
?get_sentiment
get_sentiment("eres un idiota", method="nrc", language="es")
get_sentiment("eres un idiota", method="nrc", language="spanish")
get_sentiment("eres un gran idiota", method="nrc", language="spanish")
get_sentiment("eres un gran genio", method="nrc", language="spanish")
get_sentiment("eres un gran cosa", method="nrc", language="spanish")
get_sentiment("eres un gran amigo", method="nrc", language="spanish")
get_sentiment("eres unamigo", method="nrc", language="spanish")
get_sentiment("eres un amigo", method="nrc", language="spanish")
?get_sentiments
library(schrute)
install.packages("schrute")
library(schrute)
head(theoffice)
head(theoffice$text)
theoffice %>% get_sentiments(text) %>% group_by(season)
library(dplyr)
theoffice %>% get_sentiments(text) %>% group_by(season)
theoffice$text %>% get_sentiments() %>% group_by(season)
theoffice$text %>% get_sentiments("afinn") %>% group_by(season)
theoffice$text %>% get_sentiments(lexicon = "afinn") %>% group_by(season)
theoffice %>% unnest_tokens(word, text)
theoffice %>% unnest_tokens(word, text) %>% inner_join(get_sentiments("afinn")) %>% count(word, sort=# Wed Jan 20 15:24:02 2021 ------------------------------
)
theoffice %>% unnest_tokens(word, text) %>% inner_join(get_sentiments("afinn")) %>% count(word, sort=T)
install.packages("textdata")
theoffice %>% unnest_tokens(word, text) %>% inner_join(get_sentiments("afinn")) %>% count(word, sort=T)
theoffice %>% unnest_tokens(word, text) %>% inner_join(get_sentiments("afinn"))
get_sentiments("afinn")
theoffice %>% unnest_tokens(word, text) %>% inner_join(get_sentiments("afinn")) %>% group_by(season) %>% summarize(mean(value))
get_sentiments("bing")
theoffice %>% unnest_tokens(word, text) %>% inner_join(get_sentiments("bing")) %>% group_by(season) %>% summarize(sum(sentiment=="negative"))
theoffice %>% unnest_tokens(word, text) %>% inner_join(get_sentiments("bing")) %>% group_by(season) %>% summarize(mean(sentiment=="negative"))
theoffice %>% unnest_tokens(word, text) %>% inner_join(get_sentiments("bing")) %>% group_by(season) %>% summarize(mean(sentiment=="positive"))
?unnest_tokens
library(vader)
VADERresult <- get_vader("This book is horrible, but I love it!")
head(VADERresult)
VADERresult <- get_vader("This book is horrible, but I love it")
head(VADERresult)
?get_vader
VADERresult <- get_vader("This book is horrible, but I love it!")
VADERresult
VADERresult <- get_vader("This book is horrible, but I love it very much")
VADERresult
VADERresult <- get_vader("This book is horrible, but I love it much")
VADERresult
VADERresult <- get_vader("This book is horrible, but I like it a lt")
VADERresult <- get_vader("This book is horrible, but I like it a lot")
VADERresult
VADERresult <- get_vader("This book is horrible, but I like it")
get_vader("This book is horrible, but I like it")
get_vader("This book is bad")
get_vader("This book is very bad")
get_vader("This book is somehow bad")
get_vader("This book is not bad")
get_vader("This book is horrible, but I love it!")
get_vader("This book is horrible, but I love it.")
get_vader("This book is bad")
get_vader("This book is also bad")
get_vader("This book is somehow bad")
get_vader("This book is very bad")
get_vader("This book is also also also bad")
get_vader("This book is slightly bad")
get_vader("This book is also bad")
library(schrute)
head(theoffice)
head(theoffice$text)
vader_df(head(theoffice))
?vader_df
vader_df(head(theoffice$text))
library(schrute)
texts <- head(theoffice$text)
vader_df(texts)
theoffice$vader <- vader_df(theoffice$text)$compound
library(syuzhet)
get_sentiment(hea(theoffice$text))
get_sentiment(head(theoffice$text))
?get_sentiment
get_sentiment(head(theoffice$text), method="nrc")
get_sentiment(head(theoffice$text), method="afinn")
theoffice$sentiment <- get_sentiment(theoffice$text)
theoffice %>% group_by(season) %>% summarize(mean(sentiment))
theoffice %>% group_by(season) %>% summarise(mean(sentiment))
library(dplyr)
theoffice %>% group_by(season) %>% summarise(mean(sentiment))
head(theoffice)
theoffice %>% group_by(character) %>% summarise(mean(sentiment))
theoffice %>% group_by(character) %>% summarise(mean(sentiment), n=n()) %>% order_by(desc(n)) %>% head()
theoffice %>% group_by(character) %>% summarise(mean(sentiment), n=n()) %>% order_by(n, desc=T) %>% head()
theoffice %>% group_by(character) %>% summarise(mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head()
theoffice %>% group_by(character) %>% summarise(mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head(n=10)
theoffice %>% group_by(character) %>% summarise(sent=mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head(n=40) %>% arrange(desc(sent))
theoffice %>% group_by(character) %>% summarise(sent=mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head(n=20) %>% arrange(desc(sent))
theoffice %>% group_by(character) %>% summarise(sent=mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head(n=30) %>% arrange(desc(sent))
theoffice %>% group_by(character) %>% summarise(sent=mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head(n=30) %>% arrange(desc(sent)) %>% glimpse
theoffice %>% group_by(character) %>% summarise(sent=mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head(n=30) %>% arrange(desc(sent)) -> df
View(df)
theoffice %>% group_by(character) %>% summarise(sent=mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head(n=25) %>% arrange(desc(sent)) -> df
theoffice %>% group_by(character) %>% summarise(sent=mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head(n=23) %>% arrange(desc(sent)) -> df
theoffice %>% group_by(character) %>% summarise(sent=mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head(n=20) %>% arrange(desc(sent)) -> df
library(vader)
get_vader("This book is horrible, but I love it.")
get_vader("This book is horrible, but I love it!")
get_vader("This book is bad")
get_vader("This book is also bad")
get_vader("This book is very bad")
library(schrute)
texts <- head(theoffice$text)
vader_df(texts)
get_vader("This book is not bad")
get_vader("This book is slightly bad")
library(syuzhet)
get_sentiment(head(theoffice$text))
get_sentiment(head(theoffice$text), method="afinn")
theoffice$sentiment <- get_sentiment(theoffice$text)
theoffice %>% group_by(character) %>% summarise(sent=mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head(n=20) %>% arrange(desc(sent))
library(dplyr)
theoffice$sentiment <- get_sentiment(theoffice$text)
theoffice %>% group_by(character) %>% summarise(sent=mean(sentiment), n=n()) %>% arrange(desc(n)) %>% head(n=20) %>% arrange(desc(sent))
texts <- head(theoffice$text)
text_df <- tibble(line = seq(1,6), text=texts)
text_df
texts <- head(theoffice$text)
texts
text_df <- tibble(line = seq(1,6), text=texts)
text_df
texts <- theoffice$text
texts
text_df <- tibble(character=theoffice$character, text=texts)
text_df
texts <- theoffice$text
head(texts)
text_df <- tibble(character=theoffice$character, text=texts)
head(text_df)
textdf %>% unnest_tokens(token, text) -> wordsdf
library(tidytext)
textdf %>% unnest_tokens(token, text) -> wordsdf
texts <- theoffice$text
head(texts)
textdf <- tibble(character=theoffice$character, text=texts)
head(textdf)
textdf %>% unnest_tokens(token, text) -> wordsdf
head(wordsdf)
data(stop_words)
wordsdf %>% anti_join(stop_words)
textdf %>% unnest_tokens(word, text) -> wordsdf
head(wordsdf)
data(stop_words)
wordsdf %>% anti_join(stop_words)
wordsdf %>% count(words)
wordsdf %>% count(word)
wordsdf %>% count(word) %>% arrange(desc(n))
wordsdf %>% count(word) %>% arrange(desc(n))
wordsdf %>% anti_join(stop_words)  %>% count(word) %>% arrange(desc(n))
library(dplyr)
theoffice$sentiment <- get_sentiment(theoffice$text)
theoffice %>%
group_by(character) %>%
summarise(sent=mean(sentiment), n=n()) %>%
arrange(desc(n)) %>% head(n=20) %>%
arrange(desc(sent))
data(stop_words)
wordsdf %>%
anti_join(stop_words) -> cts
wordsdf %>%
anti_join(stop_words)  %>%
count(word) %>%
arrange(desc(n)) _> cts
wordsdf %>%
anti_join(stop_words)  %>%
count(word) %>%
arrange(desc(n)) -> cts
View(cts)
wordlist <- data.frame(word=c("uh","hey","um"))
wordsdf %>%
inner_join(wordlist)  %>%
grou_by(character) %>%
count(word) %>%
arrange(desc(n))
wordlist <- data.frame(word=c("uh","hey","um"))
wordsdf %>%
inner_join(wordlist)  %>%
group_by(character) %>%
count(word) %>%
arrange(desc(n))
wordlist <- data.frame(word=c("uh","hey","um"))
wordsdf %>%
inner_join(wordlist)  %>%
group_by(character) %>%
summarize(n=n()) %>%
arrange(desc(n))
wordlist <- data.frame(word=c("uh","hey","um"))
wordsdf %>%
inner_join(wordlist)  %>%
group_by(character) %>%
summarize(nUh=n()) -> uhcount
inner_join(uhcount, charactercounts)
wordsdf %>%
count(word) %>%
arrange(desc(n)) -> charactercounts
head(charactercounts)
wordlist <- data.frame(word=c("uh","hey","um"))
wordsdf %>%
inner_join(wordlist)  %>%
group_by(character) %>%
summarize(nUh=n()) -> uhcount
inner_join(uhcount, charactercounts)
wordlist <- data.frame(word=c("uh","hey","um"))
wordsdf %>%
inner_join(wordlist)  %>%
group_by(character) %>%
summarize(nUh=n()) -> uhcount
wordsdf %>%
count(word) %>%
arrange(desc(n))
wordlist <- data.frame(word=c("uh","hey","um"))
wordsdf %>%
inner_join(wordlist)  %>%
group_by(character) %>%
summarize(nuh=n()) -> uhcount
wordsdf %>%
group_by(character) %>%
summarize(n=n()) -> charcount
inner_join(uhcount,charcount) %>% mutate(ratioUh = uhcount/charcount) %>% arrange(desc(ratioUh))
inner_join(uhcount,charcount)
wordlist <- data.frame(word=c("uh","hey","um"))
wordsdf %>%
inner_join(wordlist)  %>%
group_by(character) %>%
summarize(nuh=n()) -> uhcount
wordsdf %>%
group_by(character) %>%
summarize(n=n()) -> charcount
inner_join(uhcount,charcount) %>% mutate(ratioUh = nuh/n) %>% arrange(desc(ratioUh))
wordlist <- data.frame(word=c("uh","hey","um"))
wordsdf %>%
inner_join(wordlist)  %>%
group_by(character) %>%
summarize(nuh=n()) -> uhcount
wordsdf %>%
group_by(character) %>%
summarize(n=n()) -> charcount
inner_join(uhcount,charcount) %>% filter(n>100) %>% mutate(ratioUh = nuh/n) %>% arrange(desc(ratioUh))
wordlist <- data.frame(word=c("uh","hey","um"))
wordsdf %>%
inner_join(wordlist)  %>%
group_by(character) %>%
summarize(nuh=n()) -> uhcount
wordsdf %>%
group_by(character) %>%
summarize(n=n()) -> charcount
inner_join(uhcount,charcount) %>% filter(n>400) %>% mutate(ratioUh = nuh/n) %>% arrange(desc(ratioUh))
wordlist <- data.frame(word=c("uh","hey","um"))
wordsdf %>%
inner_join(wordlist)  %>%
group_by(character) %>%
summarize(nuh=n()) -> uhcount
wordsdf %>%
group_by(character) %>%
summarize(n=n()) -> charcount
inner_join(uhcount,charcount) %>% filter(n>5000) %>% mutate(ratioUh = nuh/n) %>% arrange(desc(ratioUh))
get_sentiments("afinn")
wordsdf %>%
inner_join(get_sentiments("afinn")) %>%
group_by(character) %>%
summarize(sent=mean(value)) -> charsentiment
charsentiment
wordsdf %>%
inner_join(get_sentiments("afinn")) %>%
group_by(character) %>%
summarize(sent=mean(value), n=n()) %>%
arrange(desc(n)) %>%
head(20) %>%
arrange(desc(sent)) -> charsentiment
View(charsentiment)
library(textdata)
lexicon_nrc_vad
lexicon_nrc_vad()
download("https://saifmohammad.com/WebDocs/VAD/NRC-VAD-Lexicon-Aug2018Release.zip")
download.file("https://saifmohammad.com/WebDocs/VAD/NRC-VAD-Lexicon-Aug2018Release.zip")
download.file("https://saifmohammad.com/WebDocs/VAD/NRC-VAD-Lexicon-Aug2018Release.zip", destfile="NRCVAD.zip")
unzip("NRCVAD.zip")
Valence <- read.table("NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/v-scores.txt", header=F)
Valence <- read.table("NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/v-scores.txt", header=F, sep="\t")
head(Valence)
vdf <- tibble(Valencedf)
Valencedf <- read.table("NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/v-scores.txt", header=F, sep="\t")
names(Valencedf) <- c("word","valence")
vdf <- tibble(Valencedf)
head(vdf)
wordsdf %>%
inner_join(vdf) %>%
group_by(character) %>%
summarize(meanvalence=mean(valence), n=n()) %>%
arrange(desc(n)) %>%
head(20) %>%
arrange(desc(sent))
wordsdf %>%
inner_join(vdf) %>%
group_by(character) %>%
summarize(meanvalence=mean(valence), n=n()) %>%
arrange(desc(n)) %>%
head(20) %>%
arrange(desc(meanvalence))
wordsdf %>%
inner_join(get_sentiments("afinn")) %>%
group_by(character) %>%
summarize(sent=mean(value), n=n()) %>%
arrange(desc(n)) %>%
head(20) %>%
arrange(desc(sent))
wordsdf %>%
inner_join(get_sentiments("afinn")) %>%
group_by(character) %>%
summarize(sent=mean(value), n=n()) %>%
arrange(desc(n)) %>%
head(20) %>%
arrange(desc(sent)) -> afinndf
afinndf
wordsdf %>%
inner_join(vdf) %>%
group_by(character) %>%
summarize(meanvalence=mean(valence), n=n()) %>%
arrange(desc(n)) %>%
head(20) %>%
arrange(desc(meanvalence)) -> nrcdf
nrcdf
joindf <- inner_join(nrcdf, afinndf)
cor.test(joindf$meanvalence, joindf$sent)
plot(joindf$meanvalence, joindf$sent)
head(joindf)
head(nrcdf)
head(afinndf)
joindf <- inner_join(nrcdf, afinndf, by="character")
plot(joindf$meanvalence, joindf$sent)
plot(joindf$meanvalence, joindf$sent, cex=log(joindf$n))
plot(joindf$meanvalence, joindf$sent, cex=log(joindf$n.x))
plot(joindf$meanvalence, joindf$sent, cex=log(joindf$n.y))
plot(joindf$meanvalence, joindf$sent, cex=sqrt(joindf$n.y))
plot(joindf$meanvalence, joindf$sent, cex=log(joindf$n.y))
plot(joindf$meanvalence, joindf$sent, cex=log(joindf$n.y)/5)
plot(joindf$meanvalence, joindf$sent, cex=log(joindf$n.y)/4)
plot(joindf$meanvalence, joindf$sent, cex=sqrt(joindf$n.y)/4)
plot(joindf$meanvalence, joindf$sent, cex=sqrt(joindf$n.y)/10)
plot(joindf$meanvalence, joindf$sent, cex=sqrt(joindf$n.y)/20)
plot(joindf$meanvalence, joindf$sent)
text(joindf$meanvalence, joindf$sent, joindf$character)
text(joindf$meanvalence, joindf$sent, joindf$character)
plot(joindf$meanvalence, joindf$sent, joindf$character)
joindf <- inner_join(nrcdf, afinndf, by="character")
plot(joindf$meanvalence, joindf$sent, pch=19)
text(joindf$meanvalence, joindf$sent, joindf$character)
joindf <- inner_join(nrcdf, afinndf, by="character")
plot(joindf$meanvalence, joindf$sent, pch=19)
text(joindf$meanvalence, joindf$sent, joindf$character)
joindf <- inner_join(nrcdf, afinndf, by="character")
plot(joindf$meanvalence, joindf$sent)
text(joindf$meanvalence, joindf$sent, joindf$character)
plot(joindf$meanvalence, joindf$sent, pch=joindf$character)
plot(joindf$meanvalence, joindf$sent, pch=joindf$character, type="n")
plot(joindf$meanvalence, joindf$sent, type="n")
joindf <- inner_join(nrcdf, afinndf, by="character")
plot(joindf$meanvalence, joindf$sent, type="n")
text(joindf$meanvalence, joindf$sent, joindf$character)
joindf <- inner_join(nrcdf, afinndf, by="character")
plot(joindf$meanvalence, joindf$sent, type="n")
text(joindf$meanvalence, joindf$sent, joindf$character)
joindf <- inner_join(nrcdf, afinndf, by="character")
plot(joindf$meanvalence, joindf$sent, type="n", xlab="NRC Valence", ylab="AFINN score")
text(joindf$meanvalence, joindf$sent, joindf$character)
cor.test(joindf$meanvalence, joindf$sent)
joindf <- inner_join(nrcdf, afinndf, by="character")
plot(joindf$meanvalence, joindf$sent, type="n", xlab="NRC Valence", ylab="AFINN score")
text(joindf$meanvalence, joindf$sent, joindf$character)
get_vader("This book is horrible, but I love it.")
library(vader)
gv <_ get_vader("This book is horrible, but I love it.")
gv <- get_vader("This book is horrible, but I love it.")
head(gv)
head(gv$w)
gv$word_
gv
gv$compoind
gv$compound
gv["compound"]
gv["word_scores"]
gv["word_scores"][1]
gv["word_scores"]+1
class(gv)
gv[1]
gv[2]
vaderres <- get_vader("This book is horrible, but I love it.")
vaderres["compound"]
get_vader("This book is bad")
get_vader("This book is slightly bad")
get_vader("This book is not bad")
library(schrute)
texts <- head(theoffice$text)
vader_df(texts)
get_sentiment("This book is horrible, but I love it!")
library(syuzhet)
get_sentiment("This book is horrible, but I love it!")
get_sentiment("This book is horrible, but I love it!")
get_sentiment("This book is horrible")
get_sentiment("This book is horrible")
get_sentiment("This book is horrible, but I love it!")
get_sentiment("This book is horrible, but I love it")
get_sentiment("This book is horrible")
get_sentiment("This book is horrible, but I love it")
get_sentiment("This book is horrible, but I love it very much")
get_sentiment("This book is horrible")
get_sentiment("This book is horrible, but I love it")
get_sentiment("This book is horrible, but I love it!")
get_sentiment(head(theoffice$text))
library(dplyr)
theoffice$sentiment <- get_sentiment(theoffice$text)
theoffice %>%
group_by(character) %>%
summarise(sent=mean(sentiment), n=n()) %>%
arrange(desc(n)) %>% head(n=20) %>%
arrange(desc(sent))
library(tidytext)
texts <- theoffice$text
head(texts)
textdf <- tibble(character=theoffice$character, text=texts)
head(textdf)
textdf %>%
unnest_tokens(word, text) -> wordsdf
head(wordsdf)
wordsdf %>%
count(word) %>%
arrange(desc(n))
?stop_words
data(stop_words)
wordsdf %>%
anti_join(stop_words)
data(stop_words)
wordsdf %>%
anti_join(stop_words)
get_sentiments("afinn")
get_sentiments("bing")
get_sentiments("nrc")
