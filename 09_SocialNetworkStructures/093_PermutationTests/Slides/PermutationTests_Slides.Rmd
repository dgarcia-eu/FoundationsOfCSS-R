---
title: "Permutation Tests"
author: "David Garcia <br><br> *TU Graz*"
date: "Foundations of Computational Social Systems"
output:
  xaringan::moon_reader:
    lib_dir: libs 
    css: [xaringan-themer.css, "libs/footer.css"]
    nature:
      beforeInit: ["libs/perc.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---


```{r xaringan-themer, include=FALSE, warning=FALSE}
#This block contains the theme configuration for the CSS lab slides style
library(xaringanthemer)
library(showtext)
style_mono_accent(
  base_color = "#5c5c5c",
  text_font_size = "1.5rem",
  header_font_google = google_font("Arial"),
  text_font_google   = google_font("Arial", "300", "300i"),
  code_font_google   = google_font("Fira Mono")
)
```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

layout: true

<div class="my-footer"><span>David Garcia - Foundations of Computational Social Systems</span></div> 

---

# Null models

Once we have measured something or got a statistical result from our analysis, we might ask ourselves: What is the probability that this result can appear due to chance alone? 

![](Coins.png)

- If the coin is fair: P(H) = 1/2 and P(HHHHH) = 1/32
- In the case of getting five heads, how plausible is that the coin is fair?

---

# Permutation tests

- Example: correlation coefficient between two variables $X$ and $Y$: $\rho(X,Y)$
- What is the probability that we could measure a similar or even stronger correlation if $X$ and $Y$ were completely independent?
- We can answer this questions with a permutation test 
- A permutation test has four components:

1. A **test statistic**,  e.g. $\rho(X,Y)$
2. A **null hypothesis**, which is a statement about the value of our test statistic when "nothing interesting happens". 
  - It is often denoted as $H_0$ and in this case it would be $H_0: \rho(X,Y)=0$.

---
# Permutation tests
1. A **test statistic**,  e.g. $\rho(X,Y)$
2. A **null hypothesis**, which is a statement about the value of our test statistic when "nothing interesting happens". 
  - It is often denoted as $H_0$ and in this case it would be $H_0: \rho(X,Y)=0$.
3. An **alternative hypothesis**, which is another statement about the value of the test statistic that stems from our theory or research question. It is often denoted as $H_1$ and, for example, it could be $H_1: \rho(X,Y)>0$. 
  - The alternative hypothesis and the null hypothesis have to be contradictory. Both can't be true at the same time, but both could be false.
4. A **permutation set** with $N$ random permutations or shuffles of the data. Permutations in this set model a world in which the null hypothesis is true and any measurement different than the one specified in the null hypothesis is due to chance alone.

---

# Permutation tests in R: FOI and GDP
```{r echo=F, message=F, results='hide', cache=TRUE}
library(WDI)
WDIdf <- WDI(indicator = c("NY.GDP.PCAP.PP.KD", "SP.POP.TOTL", "IT.NET.USER.ZS"),
             start = 2014, end = 2014, extra = TRUE)
newdf <- WDIdf[complete.cases(WDIdf) & WDIdf$region != "Aggregates",]
filteredDF <- newdf[newdf$SP.POP.TOTL*newdf$IT.NET.USER.ZS/100>5000000,] 
library(gtrendsR)
trend <- gtrends(keyword = c("2013", "2015"), time = "2014-01-01 2014-12-31")
library(dplyr)
trend$interest_by_country %>% filter(keyword=="2013") %>% select(country=location, G2013=hits) -> G2013
trend$interest_by_country %>% filter(keyword=="2015") %>% select(country=location, G2015=hits) -> G2015
gdf <- inner_join(G2013,G2015)
gdf$FOI <- gdf$G2015/gdf$G2013
mdata <- inner_join(filteredDF, gdf)
mdata$GDP <- mdata$NY.GDP.PCAP.PP.KD
mdata %>% filter(!is.na(GDP) & !is.na(FOI)) -> mdata
```

.pull-left[
- Example: correlation between the Future Orientation Index and the GDP per capita of countries

- Correlation from exercise result:
```{r, cache=TRUE, fig.width=7, fig.height=5.5}
cor(mdata$FOI, mdata$GDP)
```
]
.pull-right[
```{r, cache=TRUE, fig.width=7, fig.height=6}
plot(mdata$FOI, mdata$GDP)
```
]
---

# Permuted data

.pull-left[
- If we shuffle one of the columns:
```{r, cache=TRUE, fig.width=7, fig.height=5.5}
shufdata <- mdata[sample(nrow(mdata)),]
cor(shufdata$FOI, mdata$GDP)
```
- Idea: repeat this many times to estimate the chances of having a high correlation even though data was permuted
]
.pull-right[
```{r, cache=TRUE, fig.width=7, fig.height=6}
plot(shufdata$FOI, mdata$GDP)
```
]

---

# Permuting in a loop

We can do the permutation test in R with a loop like this:

```{r, cache=TRUE }
N <- 10000 # repeat shuffling for N times

corPerm <- numeric(length = N) 
# vector with the results of the test statistic under each permutation

for(i in 1:N)
{
 shufdata <- mdata[sample(nrow(mdata)),]
 corPerm[i] <- cor(shufdata$FOI, mdata$GDP)
}

corObserved <- cor(mdata$FOI, mdata$GDP)
```

---

# Histogram of permutation results

```{r, cache=TRUE, fig.width=10, fig.height=6, fig.align='center'}
hist(corPerm, xlim=range(c(corPerm,corObserved)))
abline(v=corObserved, col="red")
```
 
---

# The p-value of a permutation test

The p-value is a way to summarize the results of a permutation test. 

> **p-value:** Given that the null hypothesis is true, the p-value is the probability that we measure a statistic at least as extreme as the observed result

- **A common misconception is that the p-value measures the probability that the null hypothesis is true**. 

- The p-value measures the plausibility of what we measure under the null hypothesis, which is very different. 
---

# Calculating a p-value 

- *one-sided p-value*: proportion of permutations with a value of the statistic at least as large as the observed one. 
- *two-sided p-value*: proportion of permutations with an absolute value of the statistic at least as large as the observed one.


We can calculate the one-sided p-value from the permutation test:
```{r, cache=TRUE }
p_value_Cor <- (sum(corPerm>=corObserved)+1)/length(corPerm)
p_value_Cor
```
 
- We add one to the numerator to ensure we don't say zero
- The result is "significant" (p<0.05), but careful interpreting that word!
- How many times to permute: $10000$ times is safe for (p<0.05)

---

# Summary

- Social network structures
  - Triadic closure
  - The strength of weak ties
  - Structural holes and modularity
  - Small worlds


- Assortativity: when nodes have attributes
  - Assortativity coefficient
  - Three processes to generate assortative networks


- Permutation tests
  - How plausible is that I get a result as extreme as this purely by chance?
  - Permuting to simulate a null model
  - P-values as a way to summarize the result
